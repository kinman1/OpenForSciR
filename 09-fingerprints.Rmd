# Latent Fingerprints {#fingerprints}



__Abstract:__

A new measurement to quantify the quality of individual features ("minutiae") in a latent fingerprint is developed. Currently latent fingerprint quality is based on an overall global score for an entire print. However, minutiae of sufficiently high quality can be useful for identification even in prints having large sections of low fidelity. We develop a metric with a scale of 0-100 (low to high quality) that characterizes (via gradients) the clarity of ridge features, and then calculate the quality metrics on minutiae from NIST's SD27A latent fingerprint database containing prints judged by "experts" as "good," "bad," or "ugly." The proposed minutiae quality metrics correlate well with the general classification from fingerprint examiners and serve as objective, versus subjective, measures of minutiae quality. The objective quality measure enables examiners to focus on only the highest-scoring minutiae for fingerprint analyses and to discard low-scoring minutiae, thereby removing some aspects of the subjectivity involved in selecting minutiae for comparisons. We then design a procedure to determine a threshold of minutiae quality to distinguish between useful and non-useful minutiae in a forensic identification. We simulate a range of different quality prints by degrading prints of good quality images in a systematic and defined way to find the threshold below which a slated percentage of experts are unable to reliably identify fingerprint features.



## Introduction

Latent fingerprints are a common source of evidence collected at a crime scene, and have been widely used for individual identification purposes primarily because fingerprints have long been assumed to be unique to an individual. Thus it is assumed that some subset of features, or minutiae, on a latent print can be identified and will suffice to determine whether a latent print and a digital print from a database of prints collected under controlled conditions (e.g., in a police laboratory) came from the "same source." However, unlike digital fingerprints in a database, latent prints are generally of poor quality and incomplete, missing ridge structures or patterns. The quality of a latent print, needed for the "Analysis" and "Comparison" phases of the "ACE-V" ([@swgfast]) fingerprint identification process to assess clarity of the print and specific features of it for identification purposes, is currently judged visually and subjectively, rather than quantitatively, by forensic examiners. Once the examiner identifies seemingly usable minutiae on a latent print, the print is entered into an Automated Fingerprint Identification System (AFIS) which uses the examiner's minutiae to return likely matches from a fingerprint database. Thus, the accuracy of the identification depends first and foremost on the quality and usability of the minutiae in a latent. More independent, high-quality features (minutiae) should lead to more accurate calls (i.e., same or different sources, or "match" or "non-match").

* Analysis: a digitized latent print is analyzed to determine if it is "suitable" for examination. During this process, LPEs mark clear, high quality sections of a print in green, moderate quality sections in yellow, and unclear or distorted sections in red. These colors correspond to features that can be used in comparison, may possibly be used, and will not likely be useful for comparison respectfully. As level 3 detail is unreliable, LPEs use level 1 and 2 detail to determine if a print is suitable to continue to the comparison step. If not, the ACE-V process ends here.
* Comparison: the latent and exemplar prints are compared side by side. In addition to overall pattern and ridge flow, examiners may look for the existence of target groups -- unique clusters of minutiae -- that correspond between a latent and exemplar. Additional features may be marked in orange.
* Evaluation: a decision of *identification* (formerly "individualization"), *exclusion*, or *inconclusive* is made based on OSAC standards. An inconclusive conclusion may be reached if either print does not contain enough information for a decision. Examiners may request consultation with a colleague before reaching a decision, who would perform an independent markup on the latent.
* Verification: a decision may (or may not) be verified by another examiner who performs an independent markup of the latent print. If the second examiner does not know the first examiner's decision, it is considered a blind verification.

To date, neither an objective measure of quality in selected minutiae, nor the dependence among the features or the number needed for high-accuracy calls, has been considered. Quoting from Ulery et al. (2011) [@ulery_2011], "No such absolute criteria exist for judging whether the evidence is sufficient to reach a conclusion as opposed to making an inconclusive or no-value decision. The best information we have to evaluate the appropriateness of reaching a conclusion is the collective judgments of the experts." A digital fingerprint acquisition system does provide a numerical "quality" score of an "exemplar" print at the time it is taken (to ensure adequate clarity for later comparison), but the "quality" of the latent fingerprint typically is assessed qualitatively by the examiner.

Some authors have proposed measures of overall latent print quality. Bond (2008) [@bond_2008] defines a five-point scale primarily in terms of ridge continuity. Tabassi et al. (2004) [@tabassi_2004] define a five-point quality scale in terms of contrast and clarity of features tuned to a matcher's performance (high [low] quality associated with good [poor] match performance). Yoon et al. (2015) [@yoon_2015] define a latent fingerprint image quality (LFIQ) score from a user-defined set of features based on clarity of ridges and features. Tabassi et al. (2004, Section 2) [@tabassi_2004] cite other latent print quality measures that have been proposed and conclude that, for all of them, "evaluating their quality measure is a subjective matter" (p.6). Nonetheless, there remains "substantial variability in the attributes of latent prints, in the capabilities of latent print examiners, in the types of casework received by agencies, and the procedures used among agencies" (Ulery et al. 2012) [@ulery_2012]. Consequently, some procedure that offers an objective measure of minutiae quality is needed.

[[todo: add DFIQI?]]

Different features (minutiae) on a latent print supply different amounts of information to an examiner. Thus our goal is to develop a quality metric for each feature, based on a measure of information content in the feature. Visually, a feature on a print (ridge ending, bifurcation, etc.) is more recognizable when it is easily differentiated from the background around it. In the following sections we develop a quality metric for each latent fingerprint feature that quantifies its distinctiveness from its background value, and hence, how reliable a feature might be for purposes of comparison (step 2 of the ACE-V process).



## Data

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("img/fingerprint_brush.jpg")
```

One of the oldest and most common methods for recovering unseen prints is dusting. Moisture clinging powder is gently brushed onto a surface using soft brushes to detect and increase the visibility of fingerprints. Magnetic powders that cling to a metal rod instead of brush exist that may help reduce the amount of possible damage to a print that may occur during dusting. After dusting, prints are usually recorded by lifting -- placing a piece of transparent tape over the fingerprint transferring the tape along with the powder onto a card of contrasting color. Photographs may also be taken of the powdered print. In place of dusting, prints may be chemically processed (superglue, ninhydrin, Rhodamine 6G (R6G), etc.). Clearly visible prints (patent prints) such as those made by paint or blood, may be photographed directly. If the fingerprint is left on an object that is easily transported, the object should brought to the forensics lab and photographed to create a digital image.

```{r, out.width = "600px", echo = FALSE}
knitr::include_graphics("img/fingerprint_powders.png")
```

Photographs and fingerprint cards are scanned or otherwise converted to digital format. Enhancements to contrast or color may be made using a photo editing software before producing a finalized grayscale image. Digital images may then be run through an AFIS database to search for matches, directly compared to a suspects' exemplar prints (known fingerprints, e.g., those taken on a tenprint card at a police station), or run through a quality metric algorithm.

The information contained in a fingerprint can be divided into three levels [@doj_fingerprint_sourcebook].

Level 1 detail is the most general, consisting of overall pattern type, friction ridge flow, and morphological information. While insufficient for individualization, level 1 detail may be used for exclusion. "Fingerprint pattern classification" refers to overall fingerprint patterns (ex. loop, whorl) and their subcategories (ex. left/right slanted) [@hicklin_2011].

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("img/level1_detail.jpg")
```

Level 2 detail consists of minutiae and individual friction ridge paths. Minutiae are also called "Galton details," as Sir Francis Galton was the first to define and name specific minutiae (bifurcation, enclosure, ridge endings, island) [@galton_fingerprints].

```{r, out.width = "275px", echo = FALSE}
knitr::include_graphics("img/minutiae.png")
```

Level 3 detail is the most specific, including friction ridge dimensional attributes such as width, edge shapes, and pores. These details may or may not appear on an exemplar print and are the least reliable.

```{r, out.width = "400px", echo = FALSE}
knitr::include_graphics("img/level3_detail.jpg")
```

### Databases and AFIS

Latent prints may be submitted to an AFIS database which will return the top *n* potential matches. Examiners can then perform the ACE-V comparison process on these prints until a "match" is found.

IAFIS is the Integrated Automatic Fingerprint Identification System developed and maintained by the US FBI [@fbi_iafis]. Implemented in 1999, it contains criminal history, photographs, and fingerprints for over 70 million individuals with criminal histories and fingerprints of 34 million civilians [@fbi_iafis, @fbi_ngi]. The FBI's Next Generation Identification (NGI) System was announced in 2014 to extend and improve the capabilities of IAFIS. INTERPOL also maintains a database of over 181,000 fingerprint records and almost 11,000 latent prints [@interpol_fingerprints].

NIST maintains a series of Biometric Special Databases and Software [@nist_biometric], including several fingerprint databases. Special Database 302, not yet released, will contain realistic latent prints and their corresponding exemplars collected from the Intelligence Advanced Research Projects Activity (IARPA) Nail to Nail (N2N) Fingerprint Challenge [@fiumara_talk]. Annotations to these latents may be released at a future data. Special Database 27A, which has since been withdrawn, contained [[todo: check number. just under 300]] latent and exemplar print pairs that two or more LPEs have agreed "match"; i.e., print pairs not guaranteed to be ground truth matches. The latent prints in this database were classified into three categories: good, bad, and ugly, which allows for general testing of correspondence between overall fingerprint quality and global quality scores.



## Peskin and Kafadar Quality Measurement

### Quality Measurement

The algorithm identifies and examines a small collection of pixels surrounding a given feature and assesses their distinctiveness from background pixels. The underlying principle for this approach lies in recognizing that a forensic examiner can distinguish features in a fairly blurry latent print by recognizing (1) a gradient of intensity between the dark and light regions defining a minutia point, and (2) an overall contrast of intensity values in the general neighborhood of a minutiae point. The first step is to locate the pixel in a small neighborhood of the minutia location that produces the highest intensity gradient values, and then focus calculation around that pixel. The largest gradient in a neighborhood of 5 pixels in each direction from a feature location is found. For each pixel in this neighborhood, the pixel intensity, $i(x, y)$, is compared to a neighboring pixel intensity, $i(x + n, y + m)$, where $n$ and $m$ range from –2 to 2, and then divided by the corresponding distance between the pixels to get a measure of the gradient at pixel location $(x, y)$, $g(x, y; n, m)$:

$$ g(x, y; n, m) = \frac{i(x, y) - i(x + n, y + m)}{(n^2 + m^2)^{1/2}}, \qquad n, m = -2, ..., 2. $$

The set of all 24 gradients in this $5 \times 5$ neighborhood of $(x, y)$ is defined as $G_5(x, y)$. The value used for the quality measurement is the maximum value in the set $G_5(x, y)$. We define $(x_0, y_0)$ as that point that produces the largest gradient. Next we find the largest contrast between the point $(x_0, y_0)$ and its immediate $3 \times 3$ neighborhood, $(x_0 + n, y_0 + m)$, or $n_3(x_0, y_0)$, where $n$ and $m$ range from –1 to 1. The contrast factor is the largest intensity difference between $i(x_0, y_0)$ and any neighbor intensity in $n_3(x_0, y_0)$, divided by the maximum intensity in the print, $I_M$, usually 255:

$$ contrast = \frac{max\{abs(i(x_0, y_0) - i(x,y)\}}{I_M}, \qquad (x, y) \in n_3(x_0, y_0). $$

The contrast measurement differs from the gradient measurement, because it highlights the maximum change in the intensity among all 9 points surrounding the minutia point at $(x_0, y_0)$, while the gradient reflects a change in intensity near the minutia point, divided by the distance over that intensity change. Despite the simplicity of this measurement, it quantifies well the visual selection made by a forensic examiner.

To illustrate this measurement, we first look at the gradient values on a clear print with well defined minutiae. Figure 1 shows such a print. Along with it are close-up pictures of 3 minutiae in the print, where the ridge ending and bifurcations are clearly seen. One would expect these very clear minutiae to be at the high end of the quality scale when we are measuring latent minutiae quality. They are at pixel locations (97, 100), (126, 167), and (111, 68), from the upper left corner. The largest gradients at these 3 locations are 94.0, 66.5, and 88.0 intensity units per grid unit. Looking at gradient values in each $5 \times 5$ neighborhood, we find slightly higher gradient values for each minutia: 107.0, 122.0, and 121.0. For each minutia, we shift our focus point to the new $(x_0, y_0)$ corresponding with the slightly higher gradient value. For these $n_3(x_0, y_0)$ neighborhoods, we find the largest intensity differences to get the contrast. Contrast measures for the three locations are respectively, .447, .651, and .561, yielding quality metrics 107.0 $\times$ .447 = 47.84, 122.0 $\times$ .651 = 79.42, and 121.0 $\times$ .561 = 67.85. For NIST's SD27A latent fingerprint database, including all good, bad, and ugly prints for which 15008 minutia locations are defined, the range of the quality metric is 0.133-100.0 (see Table 1). A quality metric value cannot be greater than 100.0. Out of the 15008 minutia in our database, only 54 produced quality metrics over 100.0, and these scores were capped at 100.0. We now turn to the issue of applying this quality metric to determine the usability of minutiae information on a latent print.

```{r, out.width = "500px", echo = FALSE, fig.cap = "**Fig. 1.** Example of a clear fingerprint, and close-up views of 3 of the minutiae of this print. Each horizontal lines in the whole print ends at one of the minutia."}
knitr::include_graphics("img/pk_fig1.png")
```

We contrast these high quality minutiae with those on a latent print. We use the latent prints previously available on the NIST website, Database 27A of latent fingerprint minutiae. This set includes "good," "bad," and "ugly" latent prints classified by forensic examiners, and we apply our quality metric to prints in these three classes. Figure 2 shows a typical latent fingerprint from this set which has been labelled as good, bad, and ugly. Figure 3 shows a closer look at one of the highest quality minutiae on each of these three latent fingerprints.

```{r, out.width = "500px", echo = FALSE, fig.cap = "**Fig. 2.** Examples of a good, bad, and ugly latent print from the SD27A set: G043, B132, and U296."}
knitr::include_graphics("img/pk_fig2.png")
```

```{r, out.width = "500px", echo = FALSE, fig.cap = "**Fig. 3.** Examples of a good, bad, and ugly minutiae of approximately the same quality: G043: (502, 741), quality = 21.9, B132: (553, 651), quality = 27.3, and U296: (548, 655), quality = 24.3. Each minutia location is at the center of the 40 × 40 cropped image."}
knitr::include_graphics("img/pk_fig3.png")
```

To understand how our quality measure compares with an examiner's assessment, we select one of the latent prints and show minutiae that were selected by one examiner at different quality levels. Figure 4 has the minutiae from one examiner file and one of the fingerprints with a bad label, along with close-up views of three minutiae with quality measuring 5.0, 15.2, and 28.8. The gradient and contrast measures increase from left to right in these $20 \times 20$ pixel images, and the quality metric is calculated within the central one-fourth ($5 \times 5$) of the image.

```{r, out.width = "500px", echo = FALSE, fig.cap = "**Fig. 4.** One of the fingerprints labeled as bad, B110, and then an expanded view of three of the minutiae from one examiner, in order of quality: (742, 903), quality = 5.0; (727, 741), quality = 15.2; and (890, 405), quality = 28.8. For each minutiae point, the examiner location is at the center of a 20 × 20 square of pixels."}
knitr::include_graphics("img/pk_fig4.png")
```

The SD27A set of latent prints is associated with 849 sets of forensic examiner data, each an ANSI/NIST formatted record, containing locations of all minutiae. From them, we can compare our algorithm's quality metric with the examiner's assessment of "good," "bad," or "ugly." In Table 1, we tabulate the number of minutiae that a forensic examiner located in each set, and the average quality metric of all minutiae in each set. In addition to calculating the average quality metric across all minutiae on the print, we also calculate the average for only those subsets of minutiae with quality metric exceeding 10.0, 20.0, and 30.0. In each set of results, latent prints labeled "good" have more higher-scoring minutiae than prints labeled "bad" and substantially more than prints labeled "ugly." The average minutiae quality metric for each set is similar, which suggests that the assigned label of "good," "bad," or "ugly" is highly influenced by the number of distinguishable (high-scoring) minutiae on the print.

\begin{table}
	\begin{tabular}{lrrr}
		& good & bad & ugly \\
		\hline
		\multicolumn{4}{c}{All minutiae} \\
		Number of sets & 273 & 276 & 300 \\
		Number of minutiae & 7651 & 4313 & 3044 \\
		avg \#minutiae per set & 28.0 & 15.6 & 10.1 \\
		(range min, max) & (0.13,100.0) & (0.18,100.0) & (0.64-100.0) \\
		avg $Q$ per set & 24.4 & 25.4 & 24.2 \\
		(SD) & 17.1 & 18.0 & 18.4 \\
		\multicolumn{4}{c}{Minutiae with $Q > 10.0$} \\
		Number of minutiae & 6213 & 3542 & 2414 \\
		avg \#minutiae per set & 22.8 & 12.8 & 8.0 \\
		(SD) & 12.7 & 6.2 & 3.5 \\
		avg $Q$ per set & 28.5 & 29.6 & 28.9 \\
		(SD) & 16.4 & 17.1 & 17.9 \\
		\multicolumn{4}{c}{Minutiae with $Q > 20.0$} \\
		Number of minutiae & 3873 & 2331 & 1474 \\
		avg \#minutiae per set & 14.2 & 8.4 & 4.9 \\
		(SD) & 11.0 & 5.5 & 3.6 \\
		avg $Q$ per set & 36.7 & 37.3 & 37.9 \\
		(SD) & 15.7 & 16.4 & 17.5 \\
		\multicolumn{4}{c}{Minutiae with $Q > 30.0$} \\
		Number of minutiae & 2160 & 1397 & 854 \\
		avg \#minutiae & 7.9 & 5.0 & 2.8 \\
		(SD) & 8.8 & 4.4 & 3.0 \\
		avg $Q$ per set & 46.4 & 45.8 & 47.8 \\
		(SD) & 15.1 & 16.3 & 17.2 \\
	\end{tabular}
\caption{Numbers of minutiae & average minutiae quality metric ($Q$) for three sets of minutia: All sets combined and subsets defined by $Q$ (SD = standard deviation).}
\end{table}

We then compared our minutiae quality metric to the ridge quality map, which is provided in record 9.308 of the American National Standard for Information Systems data format for the Interchange of Fingerprint, Facial, and other Biometric Information [@nist_itl]. The 9.308 record contains a small grid of scores 0-5 for individual pixels on small sections of the latent print, ranked for the quality of a ridge present in that section, with 5 representing the highest score. From these grids of 0-5 values, we pulled out the ridge quality scores for individual minutia locations. We compare with our (objective) quality metric scores at those locations with the observer (subjective) ridge qualities. We made these comparisons for all 15008 of the minutia in the database. Of the 15008 minutiae, 76 scored 1, 10829 scored 2, 3940 scored 3, 144 scored 4, and 17 scored 5. The corresponding mean quality metric values for scores 1-5 are: 18.6 (measured on the 76 with scores of 1), 23.7, 26.5, 43.2, and 39.9. Corresponding standard deviation values are: 19.9, 17.1, 18.2, 26.1, and 14.8. The means and standard deviations are illustrated with a boxplot in Figure 5.

```{r, out.width = "500px", echo = FALSE, fig.cap = "**Fig. 5.** Minutiae quality vs. ridge quality for all images from the SD27A set, which include 15008 minutiae. Each box height represents the standard deviation of measurements at that ridge quality."}
knitr::include_graphics("img/pk_fig5.png")
```

### Test for usable quality

We designed a procedure to identify a threshold for this quality metric, below which the feature is unreliable, above which it may provide reliable information for comparison purposes. We systematically degraded the images of clear fingerprints and applied our algorithm to the minutiae that accompanied each degraded image. We start by recognizing that a typical clear print has background values of 255 on a scale of 0-255. Accordingly, we simulate different levels of image quality, decreasing the quality of clear prints by lowering the background intensity levels to levels lower than 255. As the background quality is lowered, the contrast between the minutiae and the background decreases. In this way, we created a series of images from each clear print of images with different levels of minutiae quality. We can then ask experts to evaluate, in a statistically designed experiment, which minutiae are, in their judgments, sufficiently distinguishable to be useful in a fingerprint analysis, and then note their conclusions following an actual search ("correct match found" or "incorrect match found"). In this way, we can estimate a range of $Q$ for minutiae that are highly correlated with accuracy of analysis. Clearly, one cannot use actual latent prints for such a study, because (a) the background on latent prints is not well characterized; and (b) "ground truth" is unknown.

Figure 6 shows an example of a clear print with background starting at 255, and then a series of prints in which the background is progressively lowered to 100. Figure 7 magnifies the region around three of the minutiae, first with background equal to 255, then with background equal to 100 to show the decreased visibility of the minutiae when the gradients and contrast are severely reduced.

```{r, out.width = "550px", echo = FALSE, fig.cap = "**Fig. 6.** A clear fingerprint on the left and then a series of transformations of that print, lowering the background intensity from 255 to 220, 200, 180, 160, 140, 120, and 100."}
knitr::include_graphics("img/pk_fig6.png")
```

```{r, out.width = "450px", echo = FALSE, fig.cap = "**Fig. 7.** Three of the minutiae from Figure 6, first with background = 255, then with background = 100."}
knitr::include_graphics("img/pk_fig7.png")
```

Given a quality metric, and a method for systematically decreasing the latent print quality, we can now design an experiment with different examiners (in terms of experience, type of training, etc.) and correlate the results of their analyses with true outcomes. If accuracy exceeds, say, 95% correct calls only when the print has at least $n_0$ minutiae having quality metrics above, say, $Q_0$, then the examiner has an objective criterion for the "A" (analysis) phase of the ACE-V process.



## Conclusions

Presently, the first step in fingerprint analysis is the analysis phase, in which the examiner assesses a print for usable minutia that are judged to be sufficiently clear and distinctive for comparison with prints in a database. To reduce the subjectivity in this assessment, we proposed in this article a "minutia quality metric" for assessing the clarity, and hence usability, of minutia (e.g., ridge endings, bifurcations, islands) in a fingerprint. The metric is scaled between 0 (totally unusable) to 100 (perfectly clear); more high-scoring minutia should lead to greater distinctiveness in the print and hence fewer false positives that can occur when trying to match latent prints to database prints using much lower-quality minutia. We showed in this article that our metric is both computationally efficient and correlates well with image quality: by systematically (via image algorithms) reducing the image quality of the print (and hence of the minutia), the quality metric declines accordingly. We also show, using NIST fingerprint images, that more high-quality minutia correlates well with the experts' three-category assessment of fingerprint images (good, bad, ugly).

In future work, we plan to evaluate the value of this algorithm for real practice, and estimate false positive and false negative rates with and without the quality metric. We report on this work in a forthcoming article.



## R Package

This R Package implements the Peskin and Kafadar Quality Measurement for quantifying the quality of individual features, or minutiae, in a latent fingerprint. The primary functions include reading in the fingerprint image into the correct format (`convert_image`) then calculating the quality scores (`quality_scores`). If desired, additional information on gradient and contrast can be output by setting `verbose = TRUE` in the `quality_scores` function. If one wishes to only see gradient and contrast values, these can be output by functions `find_maxgrad` and `find_contrast`, respectively.

https://github.com/kdp4be/fingerprint_package

```{r, echo = TRUE, eval = FALSE}
library(bmp)

temp_image <- read.bmp("data/G080.bmp")
temp_min <- read.csv("data/G080_min.txt", header = TRUE, sep = ",")

image_file <- convert_image(temp_image, "bmp")
#min_file <- import_features(temp_min)
min_file <- as.matrix(temp_min[, c(2, 3)])

# assumes columns 1, 2 of minutiae file are x, y pixel locations
quality_scores(image_file, min_file)
quality_scores(image_file, min_file, verbose = TRUE)

# if image already in pixel array format, must be transposed before running quality_scores
text_image <- read.csv("data/G080.txt", header = FALSE, sep = "\t")
quality_scores(t(text_image), min_file)
```



## Case Study

[[todo: is the section above on sd27a prints considered enough of a case study? if so can remove the following, and relabel half of the quality metric section to case study. "to illustrate..."]]

```{r, out.width = "650px", echo = FALSE}
knitr::include_graphics("img/fingerprint_card.png")
```

Five simple fingerprints were created on a clean glass plate using a single finger with differing levels of pressure. These levels range from one to five, with one indicating the largest amount of pressure applied. The glass plate was dusted using a black magnetic powder and the revealed prints lifted with tape onto the back of a white fingerprint card. As expected, as pressure decreases, the latents decrease in overall quality (visually, the ridges are less thick and lose some continuity) and amount of friction ridge area captured. The entire fingerprint card was scanned and each print was cropped into its own grayscale image file. These cropped images were converted into their equivalent 2D pixel array values (0 to 255, black to white).

Five minutiae (ridge endings (E) and bifurcations (B)) from the second and third prints were analyzed using the Peskin and Kafadar algorithm. As contrast is a [main] feature of the algorithm, the darker, blacker ridges as seen in the first image below receive overall higher scores than the lighter gray ridges in the second image (minutiae 3 is an exception).

<style type="text/css">
.twoC {width: 80%}
.clearer {clear: both}
.twoC .table {max-width: 40%; float: right}
.twoC img {max-width: 40%; float: left}
</style>

<div class="twoC">
```{r out.width = "200px", echo = FALSE}
knitr::include_graphics("img/print_case_study_2.bmp")
```
```{r echo=FALSE}
library(kableExtra)
pk_scores <- data.frame(1:5, c("E", "B", "E", "E", "B"), c(70.27, 57.76, 54.99, 58.32, 54.78))
colnames(pk_scores) <- c("Feature", "Type", "Score")
kableExtra::kable(pk_scores, align=rep('c', 5)) %>% kable_styling(full_width = F)
```
</div>
<div class="clearer"></div>

<div class="twoC">
```{r out.width = "200px", echo = FALSE}
knitr::include_graphics("img/print_case_study_3.bmp")
```
```{r echo=FALSE}
library(kableExtra)
pk_scores <- data.frame(1:5, c("E", "B", "E", "E", "B"), c(29.46, 19.99, 79.86, 20.97, 23.79))
colnames(pk_scores) <- c("Feature", "Type", "Score")
kableExtra::kable(pk_scores, align=rep('c', 5)) %>% kable_styling(full_width = F)
```
</div>
<div class="clearer"></div>



## Acknowledgements

[[todo: We would like to acknowledge Dr. Adele Peskin, who was vital in the development and implementation of the Peskin and Kafadar Quality Measurement Algorithm.]]
