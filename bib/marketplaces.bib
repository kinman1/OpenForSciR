% Encoding: UTF-8

@Book{Kruithof2016,
  title     = {Internet-facilitated drugs trade: An analysis of the size, scope and the role of the Netherlands},
  publisher = {RAND Corporation},
  year      = {2016},
  author    = {Kruithof, Kristy and Judith Aldridge and David D\'ecary H\'etu and Megan Sim and Elma Dujso and Stijn Hoorens},
  address   = {Santa Monica, CA},
  url       = {https://www.rand.org/pubs/research_reports/RR1607.html},
}

@InProceedings{Soska2015,
  author    = {Soska, Kyle and Christin, Nicolas},
  title     = {Measuring the Longitudinal Evolution of the Online Anonymous Marketplace Ecosystem},
  booktitle = {Proceedings of the 24th USENIX Conference on Security Symposium},
  year      = {2015},
  series    = {SEC'15},
  pages     = {33--48},
  address   = {Berkeley, CA, USA},
  publisher = {USENIX Association},
  acmid     = {2831146},
  isbn      = {978-1-931971-232},
  location  = {Washington, D.C.},
  numpages  = {16},
  url       = {http://dl.acm.org/citation.cfm?id=2831143.2831146},
}

@InProceedings{Kumar2017,
  author    = {Kumar, Srijan and Cheng, Justin and Leskovec, Jure and Subrahmanian, V.S.},
  title     = {An Army of Me: Sockpuppets in Online Discussion Communities},
  booktitle = {Proceedings of the 26th International Conference on World Wide Web},
  year      = {2017},
  series    = {WWW '17},
  pages     = {857--866},
  address   = {Republic and Canton of Geneva, Switzerland},
  publisher = {International World Wide Web Conferences Steering Committee},
  acmid     = {3052677},
  doi       = {10.1145/3038912.3052677},
  isbn      = {978-1-4503-4913-0},
  keywords  = {antisocial behavior, malicious users, multiple account use},
  location  = {Perth, Australia},
  numpages  = {10},
  url       = {https://doi.org/10.1145/3038912.3052677},
}

@Article{Broseus2016,
  author   = {J. Bros\'{e}us and D. Rhumorbarbe and C. Mireault and V. Ouellette and F. Crispino and D. D\'ecary-H\'etu},
  title    = {Studying illicit drug trafficking on Darknet markets: Structure and organisation from a Canadian perspective},
  journal  = {Forensic Science International},
  year     = {2016},
  volume   = {264},
  pages    = {7 - 14},
  issn     = {0379-0738},
  note     = {Special Issue on the 7th European Academy of Forensic Science Conference},
  abstract = {Cryptomarkets are online marketplaces that are part of the Dark Web and mainly devoted to the sale of illicit drugs. They combine tools to ensure anonymity of participants with the delivery of products by mail to enable the development of illicit drug trafficking. Using data collected on eight cryptomarkets, this study provides an overview of the Canadian illicit drug market. It seeks to inform about the most prevalent illicit drugs vendors offer for sale and preferred destination countries. Moreover, the research gives an insight into the structure and organisation of distribution networks existing online. In particular, we provide information about how vendors are diversifying and replicating across marketplaces. We inform on the number of listings each vendor manages, the number of cryptomarkets they are active on and the products they offer. This research demonstrates the importance of online marketplaces in the context of illicit drug trafficking. It shows how the analysis of data available online may elicit knowledge on criminal activities. Such knowledge is mandatory to design efficient policy for monitoring or repressive purposes against anonymous marketplaces. Nevertheless, trafficking on Dark Net markets is difficult to analyse based only on digital data. A more holistic approach for investigating this crime problem should be developed. This should rely on a combined use and interpretation of digital and physical data within a single collaborative intelligence model.},
  doi      = {http://dx.doi.org/10.1016/j.forsciint.2016.02.045},
  keywords = {Digital data, Cybercrime, Intelligence, Criminal evolution, TOR, PGP key},
  url      = {http://www.sciencedirect.com/science/article/pii/S0379073816300676},
}

@Article{Dolliver2016,
  author   = {Diana S. Dolliver and Jennifer L. Kenney},
  title    = {Characteristics of Drug Vendors on the Tor Network: A Cryptomarket Comparison},
  journal  = {Victims \& Offenders},
  year     = {2016},
  volume   = {11},
  number   = {4},
  pages    = {600-620},
  abstract = { AbstractPast research on drug-related vendors on Tor marketplaces indicate that sellers are motivated by the greater anonymity afforded by the Tor Network. Limited research has even posited that some drug-related vendors on cryptomarkets sell to other dealers, adding another dimension to existing literature that highlights the retail nature (dealer-to-customer transactions) of these Tor-based drug markets. Yet these past studies have been largely qualitative in nature. This study conducted a quantitative analysis of vendor accounts on Evolution and Agora to determine characteristics predictive of vendors advertising controlled substances, and to determine whether any statistically significant differences among drug vendor characteristics existed between the two sites. },
  doi      = {10.1080/15564886.2016.1173158},
  eprint   = {http://dx.doi.org/10.1080/15564886.2016.1173158},
  url      = { 
        http://dx.doi.org/10.1080/15564886.2016.1173158
    
},
}

@Article{Buskirk2017,
  author   = {Joe Van Buskirk and Raimondo Bruno and Timothy Dobbins and Courtney Breen and Lucinda Burns and Sundresan Naicker and Amanda Roxburgh},
  title    = {The recovery of online drug markets following law enforcement and other disruptions},
  journal  = {Drug and Alcohol Dependence},
  year     = {2017},
  volume   = {173},
  pages    = {159 - 162},
  issn     = {0376-8716},
  abstract = {AbstractIntroduction Online drug markets operating on the ‘darknet’ (‘cryptomarkets’) facilitate the trade of illicit substances at an international level. The present study assessed the longitudinal impact on cryptomarket trading of two major disruptions: a large international law enforcement operation, ‘Operation Onymous’; and the closure of the largest cryptomarket, Evolution. Methods Almost 1150 weekly snapshots of a total of 39 cryptomarkets were collected between October 2013 and November 2015. Data were collapsed by month and the number of unique vendor aliases operating across markets was assessed using interrupted time series regression. Results Following both Operation Onymous and the closure of Evolution, significant drops of 627 (p = 0.014) and 910 vendors (p &lt; 0.001) were observed, respectively. However, neither disruption significantly affected the rate at which vendor numbers increased overall. Conclusions Operation Onymous and the closure of Evolution were associated with considerable, though temporary, reductions in the number of vendors operating across cryptomarkets. Vendor numbers, however, recovered at a constant rate. While these disruptions likely impacted cryptomarket trading at the time, these markets appear resilient to disruption long-term. },
  doi      = {https://doi.org/10.1016/j.drugalcdep.2017.01.004},
  keywords = {Online drug markets, Cryptomarkets, Darknet, Illicit drug trade, New drug markets, Law enforcement },
  url      = {http://www.sciencedirect.com/science/article/pii/S0376871617300741},
}

@InProceedings{Baravalle2016,
  author    = {A. Baravalle and M. S. Lopez and S. W. Lee},
  title     = {Mining the Dark Web: Drugs and Fake Ids},
  booktitle = {2016 IEEE 16th International Conference on Data Mining Workshops (ICDMW)},
  year      = {2016},
  pages     = {350-356},
  month     = {Dec},
  abstract  = {In the last years, governmental bodies have been futilely trying to fight against dark web marketplaces. Shortly after the closing of "The Silk Road" by the FBI and Europol in 2013, new successors have been established. Through the combination of cryptocurrencies and nonstandard communication protocols and tools, agents can anonymously trade in a marketplace for illegal items without leaving any record. This paper presents a research carried out to gain insights on the products and services sold within one of the larger marketplaces for drugs, fake ids and weapons on the Internet, Agora. Our work sheds a light on the nature of the market, there is a clear preponderance of drugs, which accounts for nearly 80% of the total items on sale. The ready availability of counterfeit documents, while they make up for a much smaller percentage of the market, raises worries. Finally, the role of organized crime within Agora is discussed and presented.},
  doi       = {10.1109/ICDMW.2016.0056},
  keywords  = {Internet;data mining;law administration;security of data;Agora;Europol;FBI;Internet;The Silk Road;counterfeit documents;cryptocurrencies;dark Web marketplaces;dark Web mining;drugs;fake ids;governmental bodies;illegal item marketplace;nonstandard communication protocols;Data collection;Data mining;Drugs;Internet;Roads;Weapons;Web sites;authomation;bitcoins;dark web;data wrangling;etl processing;security;tor},
}

@Article{Tsikerdekis2014,
  author     = {Tsikerdekis, Michail and Zeadally, Sherali},
  title      = {Online Deception in Social Media},
  journal    = {Commun. ACM},
  year       = {2014},
  volume     = {57},
  number     = {9},
  pages      = {72--80},
  month      = sep,
  issn       = {0001-0782},
  acmid      = {2629612},
  address    = {New York, NY, USA},
  doi        = {10.1145/2629612},
  issue_date = {September 2014},
  numpages   = {9},
  publisher  = {ACM},
  url        = {http://doi.acm.org/10.1145/2629612},
}

@Article{Ventura2015,
  author   = {Samuel L. Ventura and Rebecca Nugent and Erica R.H. Fuchs},
  title    = {Seeing the non-stars: (Some) sources of bias in past disambiguation approaches and a new public tool leveraging labeled records},
  journal  = {Research Policy},
  year     = {2015},
  volume   = {44},
  number   = {9},
  pages    = {1672 - 1701},
  issn     = {0048-7333},
  note     = {The New Data Frontier},
  abstract = {To date, methods used to disambiguate inventors in the United States Patent and Trademark Office (USPTO) database have been rule- and threshold-based (requiring and leveraging expert knowledge) or semi-supervised algorithms trained on statistically generated artificial labels. Using a large, hand-disambiguated set of 98,762 labeled USPTO inventor records from the field of optoelectronics consisting of four sub-samples of inventors with varying characteristics (Akinsanmi et al., 2014) and a second large, hand-disambiguated set of 53,378 labeled inventor records corresponding to a subset of academics in the life sciences (Azoulay et al., 2012), we provide the first supervised learning approach for USPTO inventor disambiguation. Using these two sets of inventor records, we also provide extensive evaluations of both our algorithm and three examples of prior approaches to USPTO disambiguation arguably representative of the range of approaches used to-date. We show that the three past disambiguation algorithms we evaluate demonstrate biases depending on the feature distribution of the target disambiguation population. Both the rule- and threshold-based methods and the semi-supervised approach perform poorly (10–22% false negative error rates) on a random sample of optoelectronics inventors – arguably the closest of our sub-samples to what might be expected of the majority of inventors in the USPTO (based on disambiguation-relevant metrics). The supervised learning approach, using random forests and trained on our labeled optoelectronics dataset, consistently maintains error rates below 3% across all of our available samples. We make public both our labeled optoelectronics inventor records and our code to build supervised learning models and disambiguate inventors (see http://www.cmu.edu/epp/disambiguation). Our code also allows users to implement supervised learning approaches with their own representative labeled training data.},
  doi      = {http://dx.doi.org/10.1016/j.respol.2014.12.010},
  keywords = {Record linkage, Disambiguation, Patents, Supervised learning, Random forests},
  url      = {http://www.sciencedirect.com/science/article/pii/S0048733314002406},
}

@InProceedings{Leontiadis2013,
  author    = {Leontiadis, Nektarios and Moore, Tyler and Christin, Nicolas},
  title     = {Pick Your Poison: Pricing and Inventories at Unlicensed Online Pharmacies},
  booktitle = {Proceedings of the Fourteenth ACM Conference on Electronic Commerce},
  year      = {2013},
  series    = {EC '13},
  pages     = {621--638},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2482610},
  doi       = {10.1145/2482540.2482610},
  isbn      = {978-1-4503-1962-1},
  keywords  = {online crime, pharmacies, search-engine poisoning, web frauds},
  location  = {Philadelphia, Pennsylvania, USA},
  numpages  = {18},
  url       = {http://doi.acm.org/10.1145/2482540.2482610},
}

@Book{Christen2012,
  title     = {Data Matching: Concepts and Techniques for Record Linkage, Entity Resolution, and Duplicate Detection},
  publisher = {Springer Publishing Company, Incorporated},
  year      = {2012},
  author    = {Christen, Peter},
  isbn      = {3642311636, 9783642311635},
}

@Article{Copas1990,
  author    = {J. B. Copas and F. J. Hilton},
  title     = {Record Linkage: Statistical Models for Matching Computer Records},
  journal   = {Journal of the Royal Statistical Society. Series A (Statistics in Society)},
  year      = {1990},
  volume    = {153},
  number    = {3},
  pages     = {287-320},
  issn      = {09641998, 1467985X},
  abstract  = {We wish to measure the evidence that a pair of records relates to the same, rather than different, individuals. The paper emphasizes statistical models which can be fitted to a file of record pairs known to be correctly matched, and then used to estimate likelihood ratios. A number of models are developed and applied to UK immigration statistics. The combination of likelihood ratios for possibly correlated record fields is discussed.},
  publisher = {[Wiley, Royal Statistical Society]},
  url       = {http://www.jstor.org/stable/2982975},
}
﻿

@Article{Skinner2007,
  author    = {Skinner, C. J.},
  title     = {The probability of identification: applying ideas from forensic statistics to disclosure risk assessment},
  journal   = {Journal of the Royal Statistical Society: Series A (Statistics in Society)},
  year      = {2007},
  volume    = {170},
  number    = {1},
  pages     = {195--212},
  issn      = {1467-985X},
  abstract  = {Summary.  The paper establishes a correspondence between statistical disclosure control and forensic statistics regarding their common use of the concept of ‘probability of identification’. The paper then seeks to investigate what lessons for disclosure control can be learnt from the forensic identification literature. The main lesson that is considered is that disclosure risk assessment cannot, in general, ignore the search method that is employed by an intruder seeking to achieve disclosure. The effects of using several search methods are considered. Through consideration of the plausibility of assumptions and ‘worst case’ approaches, the paper suggests how the impact of search method can be handled. The paper focuses on foundations of disclosure risk assessment, providing some justification for some modelling assumptions underlying some existing record level measures of disclosure risk. The paper illustrates the effects of using various search methods in a numerical example based on microdata from a sample from the 2001 UK census.},
  doi       = {10.1111/j.1467-985X.2006.00457.x},
  keywords  = {Confidentiality, Disclosure control, Microdata, Record linkage, Uniqueness},
  publisher = {Blackwell Publishing Ltd},
  url       = {http://dx.doi.org/10.1111/j.1467-985X.2006.00457.x},
}

@Article{Fellegi1969,
  author        = {Ivan P. Fellegi and Alan B. Sunter},
  title         = {A Theory for Record Linkage},
  journal       = {Journal of the American Statistical Association},
  year          = {1969},
  volume        = {64},
  number        = {328},
  pages         = {1183-1210},
  __markedentry = {[xtai:]},
  abstract      = { Abstract A mathematical model is developed to provide a theoretical framework for a computer-oriented solution to the problem of recognizing those records in two files which represent identical persons, objects or events (said to be matched). A comparison is to be made between the recorded characteristics and values in two records (one from each file) and a decision made as to whether or not the members of the comparison-pair represent the same person or event, or whether there is insufficient evidence to justify either of these decisions at stipulated levels of error. These three decisions are referred to as link (A 1), a non-link (A 3), and a possible link (A 2). The first two decisions are called positive dispositions. The two types of error are defined as the error of the decision A 1 when the members of the comparison pair are in fact unmatched, and the error of the decision A 3 when the members of the comparison pair are, in fact matched. The probabilities of these errors are defined as and respectively where u(γ), m(γ) are the probabilities of realizing γ (a comparison vector whose components are the coded agreements and disagreements on each characteristic) for unmatched and matched record pairs respectively. The summation is over the whole comparison space r of possible realizations. A linkage rule assigns probabilities P(A 1|γ), and P(A 2|γ), and P(A 3|γ) to each possible realization of γ ε Γ. An optimal linkage rule L (μ, λ, Γ) is defined for each value of (μ, λ) as the rule that minimizes P(A 2) at those error levels. In other words, for fixed levels of error, the rule minimizes the probability of failing to make positive dispositions. A theorem describing the construction and properties of the optimal linkage rule and two corollaries to the theorem which make it a practical working tool are given. },
  doi           = {10.1080/01621459.1969.10501049},
  eprint        = {http://amstat.tandfonline.com/doi/pdf/10.1080/01621459.1969.10501049},
  url           = { 
        http://amstat.tandfonline.com/doi/abs/10.1080/01621459.1969.10501049
    
},
}

@InProceedings{Winkler2000UsingTE,
  author = {William E. Winkler},
  title  = {Using the EM Algorithm for Weight Computation in the Felligi-Sunter Model of Record Linkage},
  year   = {2000},
}

@Article{Hepler2012,
  author        = {Amanda B. Hepler and Christopher P. Saunders and Linda J. Davis and JoAnn Buscaglia},
  title         = {Score-based likelihood ratios for handwriting evidence},
  journal       = {Forensic Science International},
  year          = {2012},
  volume        = {219},
  number        = {1},
  pages         = {129 - 140},
  issn          = {0379-0738},
  __markedentry = {[xtai:6]},
  doi           = {http://dx.doi.org/10.1016/j.forsciint.2011.12.009},
  keywords      = {Forensic science, Likelihood ratio, Handwriting evidence, Statistical evidence evaluation, Forensic statistics, Questioned documents},
  url           = {http://www.sciencedirect.com/science/article/pii/S0379073811006013},
}

@InProceedings{Sarawagi2002,
  author    = {Sarawagi, Sunita and Bhamidipaty, Anuradha},
  title     = {Interactive Deduplication Using Active Learning},
  booktitle = {Proceedings of the Eighth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
  year      = {2002},
  series    = {KDD '02},
  pages     = {269--278},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {775087},
  doi       = {10.1145/775047.775087},
  isbn      = {1-58113-567-X},
  location  = {Edmonton, Alberta, Canada},
  numpages  = {10},
  url       = {http://doi.acm.org/10.1145/775047.775087},
}

@Article{Frenay2014,
  author   = {B. Frenay and M. Verleysen},
  title    = {Classification in the Presence of Label Noise: A Survey},
  journal  = {IEEE Transactions on Neural Networks and Learning Systems},
  year     = {2014},
  volume   = {25},
  number   = {5},
  pages    = {845-869},
  month    = {May},
  issn     = {2162-237X},
  abstract = {Label noise is an important issue in classification, with many potential negative consequences. For example, the accuracy of predictions may decrease, whereas the complexity of inferred models and the number of necessary training samples may increase. Many works in the literature have been devoted to the study of label noise and the development of techniques to deal with label noise. However, the field lacks a comprehensive survey on the different types of label noise, their consequences and the algorithms that consider label noise. This paper proposes to fill this gap. First, the definitions and sources of label noise are considered and a taxonomy of the types of label noise is proposed. Second, the potential consequences of label noise are discussed. Third, label noise-robust, label noise cleansing, and label noise-tolerant algorithms are reviewed. For each category of approaches, a short discussion is proposed to help the practitioner to choose the most suitable technique in its own particular field of application. Eventually, the design of experiments is also discussed, what may interest the researchers who would like to test their own algorithms. In this paper, label noise consists of mislabeled instances: no additional information is assumed to be available like e.g., confidences on labels.},
  doi      = {10.1109/TNNLS.2013.2292894},
  keywords = {learning (artificial intelligence);pattern classification;label noise classification;label noise cleansing algorithm;label noise-robust algorithm;label noise-tolerant algorithms;machine learning;potential negative consequences;Context;Labeling;Noise;Noise measurement;Reliability;Taxonomy;Training;Class noise;classification;label noise;mislabeling;robust methods;survey;survey.},
}

@Misc{Popper2017,
  author       = {Nathaniel Popper},
  title        = {Opioid Dealers Embrace the Dark Web to Send Deadly Drugs by Mail},
  howpublished = {\url{https://www.nytimes.com/2017/06/10/business/dealbook/opioid-dark-web-drug-overdose.html}, accessed: 2017-08-20},
  year         = {2017},
}

@Misc{UniStatesDistrictCourt2016,
  author       = {{United States District Court, Eastern District of New York}},
  title        = {Affidavit in Support of Removal to the Eastern District of California},
  howpublished = {\url{https://regmedia.co.uk/2016/08/12/almashwali_arrest.pdf}, accessed 2017-08-20},
  year         = {2016},
  note         = {dark51},
}

@Misc{DNP2017,
  author       = {{Dutch National Police}},
  howpublished = {\url{http://politiepcvh42eav.onion/hansafaq.html}, accessed 2017-08-20},
  year         = {2017},
}

@Misc{UniStatesDistrictCourt2016a,
  author       = {{United States District Court, Eastern District of California}},
  title        = {Affidavit of Matthew Larsen},
  howpublished = {\url{https://www.justice.gov/usao-edca/file/836576/download}, accessed 2017-08-20},
  year         = {2016},
  note         = {caliconnect},
}

@Misc{UniStatesDistrictCourt2017a,
  author       = {{United States District Court, Eastern District of California}},
  title        = {Criminal Complaint},
  howpublished = {\url{http://ia601509.us.archive.org/10/items/gov.uscourts.caed.320736/gov.uscourts.caed.320736.11.0.pdf}, accessed 2017-08-20},
  year         = {2017},
  note         = {PureFireMeds --> HumboldtFarms},
}

@Misc{Popper2015,
  author       = {Nathaniel Popper},
  title        = {The Tax Sleuth Who Took Down a Drug Lord},
  howpublished = {\url{https://www.nytimes.com/2015/12/27/business/dealbook/the-unsung-tax-agent-who-put-a-face-on-the-silk-road.html?mcubz=1}, accessed 2017-08-20},
  year         = {2015},
}

@Article{Christen2012a,
  author   = {P. Christen},
  title    = {A Survey of Indexing Techniques for Scalable Record Linkage and Deduplication},
  journal  = {IEEE Transactions on Knowledge and Data Engineering},
  year     = {2012},
  volume   = {24},
  number   = {9},
  pages    = {1537-1555},
  month    = {Sept},
  issn     = {1041-4347},
  abstract = {Record linkage is the process of matching records from several databases that refer to the same entities. When applied on a single database, this process is known as deduplication. Increasingly, matched data are becoming important in many application areas, because they can contain information that is not available otherwise, or that is too costly to acquire. Removing duplicate records in a single database is a crucial step in the data cleaning process, because duplicates can severely influence the outcomes of any subsequent data processing or data mining. With the increasing size of today's databases, the complexity of the matching process becomes one of the major challenges for record linkage and deduplication. In recent years, various indexing techniques have been developed for record linkage and deduplication. They are aimed at reducing the number of record pairs to be compared in the matching process by removing obvious nonmatching pairs, while at the same time maintaining high matching quality. This paper presents a survey of 12 variations of 6 indexing techniques. Their complexity is analyzed, and their performance and scalability is evaluated within an experimental framework using both synthetic and real data sets. No such detailed survey has so far been published.},
  doi      = {10.1109/TKDE.2011.127},
  keywords = {Complexity theory;Couplings;Encoding;Indexing;Data linkage;blocking;data matching;entity resolution;experimental evaluation;index techniques;scalability},
}

@Standard{Liaw2002,
  title   = {Classification and regression by randomForest},
  author  = {Liaw, Andy and Wiener, Matthew and others},
  number  = {3},
  year    = {2002},
  journal = {R news},
  pages   = {18--22},
  volume  = {2},
}

@InProceedings{Wang2018,
  author    = {Wang, Xiangwen and Peng, Peng and Wang, Chun and Wang, Gang},
  title     = {You Are Your Photographs: Detecting Multiple Identities of Vendors in the Darknet Marketplaces},
  booktitle = {Proceedings of the 2018 on Asia Conference on Computer and Communications Security},
  year      = {2018},
  series    = {ASIACCS '18},
  pages     = {431--442},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {3196529},
  doi       = {10.1145/3196494.3196529},
  isbn      = {978-1-4503-5576-6},
  keywords  = {darknet market, image analysis, stylometry, sybil detection},
  location  = {Incheon, Republic of Korea},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/3196494.3196529},
}

@Article{Murtagh2012,
  author   = {Murtagh, Fionn and Contreras, Pedro},
  title    = {Algorithms for hierarchical clustering: an overview},
  journal  = {Wiley Interdisciplinary Reviews: Data Mining and Knowledge Discovery},
  year     = {2012},
  volume   = {2},
  number   = {1},
  pages    = {86-97},
  abstract = {Abstract We survey agglomerative hierarchical clustering algorithms and discuss efficient implementations that are available in R and other software environments. We look at hierarchical self-organizing maps, and mixture models. We review grid-based clustering, focusing on hierarchical density-based approaches. Finally, we describe a recently developed very efficient (linear time) hierarchical clustering algorithm, which can also be viewed as a hierarchical grid-based algorithm. © 2011 Wiley Periodicals, Inc. This article is categorized under: Algorithmic Development > Hierarchies and Trees Technologies > Structure Discovery and Clustering},
  doi      = {10.1002/widm.53},
  eprint   = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/widm.53},
  url      = {https://onlinelibrary.wiley.com/doi/abs/10.1002/widm.53},
}

@Article{Bien2011,
  author  = {Jacob Bien and Robert Tibshirani},
  title   = {Hierarchical Clustering With Prototypes via Minimax Linkage.},
  journal = {Journal of the American Statistical Association},
  year    = {2011},
  volume  = {106 495},
  pages   = {1075-1084},
}

@TechReport{Winkler2006,
  author      = {William E Winkler},
  title       = {Overview of record linkage and current research directions},
  institution = {BUREAU OF THE CENSUS},
  year        = {2006},
}

@Article{Sokal1958,
  author    = {Sokal, R. R. and Michener, C. D.},
  title     = {A statistical method for evaluating systematic relationships},
  journal   = {University of Kansas Science Bulletin},
  year      = {1958},
  volume    = {38},
  pages     = {1409-1438},
  added-at  = {2009-01-22T02:55:58.000+0100},
  biburl    = {https://www.bibsonomy.org/bibtex/2e98b6932b71117001ddc4a22b5538532/stephane.guindon},
  interhash = {a545d67fd4603f81e7aae176bf1507c0},
  intrahash = {e98b6932b71117001ddc4a22b5538532},
  keywords  = {imported},
  timestamp = {2009-01-22T07:35:18.000+0100},
}

@InProceedings{Christin2013,
  author    = {Christin, Nicolas},
  title     = {Traveling the Silk Road: A Measurement Analysis of a Large Anonymous Online Marketplace},
  booktitle = {Proceedings of the 22Nd International Conference on World Wide Web},
  year      = {2013},
  series    = {WWW '13},
  pages     = {213--224},
  address   = {New York, NY, USA},
  publisher = {ACM},
  acmid     = {2488408},
  doi       = {10.1145/2488388.2488408},
  isbn      = {978-1-4503-2035-1},
  keywords  = {anonymity, electronic commerce, online crime},
  location  = {Rio de Janeiro, Brazil},
  numpages  = {12},
  url       = {http://doi.acm.org/10.1145/2488388.2488408},
}

@Comment{jabref-meta: databaseType:bibtex;}
