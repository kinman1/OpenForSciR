# Firearms: casings {#casings}

## Introduction

Marks are left on cartridge cases due to the firing process of a gun, in a similar way that marks are left on bullets. In the case of cartridge cases, there are at least two types of marks that are of interest. First, the firing pin hits the primer material at the base of the cartridge, leaving a firing pin impression. The subsequent explosion (which launches the bullet) also causes the cartridge case to be pressed against the breech block of the gun, leaving impressed marks known as breechface marks. Both these types of marks are thought to individualize a gun, hence law enforcement officers frequently collect cartridge cases from crime scenes, in hopes of connecting these to retrieved guns, or connecting crime scenes where the same weapon was used.

In current practice, retrieved cartridge cases are entered into a national database called the National Integrated Ballistics Information Network (NIBIN), through a computer-based platform which was developed and is maintained by Ultra Electronics Forensic Technology (FTI). This platform captures an image of the "new" cartridge case and runs a proprietary search algorithm, returning a list of top ranked potential matches from the database. Firearms examiners then examine this list and the associated images, to make a judgment about which potential matches warrant further investigation. The physical cartridge cases associated with these images are then located and examined under a comparison microscope. The firearms examiner decides if there are any matches, based on whether there is "sufficient agreement" between the marks [@AFTE1992], and may bring this evidence to court.

There has been much public criticism in recent years about the current system. For example, PCAST [@PCAST2016] expressed concern that there had been insufficient studies establishing the reliability of conclusions made by examiners, and the associated error rates had not been adequately estimated. They suggested two directions for the path forward. The first is to "continue to improve firearms analysis as a subjective method," and the second is to "convert firearms analysis from a subjective method to an objective method," through the use of automated methods and image-analysis algorithms.

There have been efforts by various groups, both commercial and academic, in line with this second recommendation. A full review is out of the scope of the current text, but we refer the interested reader to @Roth2015, @Geradts2001, @Thumwarin2008, @Riva2014, @Vorburger2007, @Song2013, and others. One point to note is that as far as we know, none of these methods are open-source. We have developed methodology to process and compare cartridge cases in a fully automatic manner, and in this chapter, we describe R packages to accomplish these tasks.


## Data 
NIST maintains a Ballistics Toolmark Research Database (https://tsapps.nist.gov/NRBTD), an open-access research database of bullet and cartridge case toolmark data. The database contains images from test fires originating from studies conducted by various groups in the firearm and toolmark community. These cartridge cases were originally conducted for different purposes, for example the Laura Lightstone study investigated whether firearms examiners were able to differentiate cartridge cases from consecutively manufactured pistol slides [@Lightstone2010]. Majority of the data available are of cartridge cases that were sent to NIST for imaging, but the website also allows users to upload their own data in a standardized format.

There are a total of 2305 images (as of 8/21/2018) **[[update figure]]**, and among these are data sets involving consecutively manufactured pistol slides, a large number of firings (termed persistence studies because they investigate the persistence of marks), as well as different makes and models of guns and ammunition. Gun manufacturers include Glock, Hi-Point, Ruger, Sig Sauer, and Smith \& Wesson, and ammunition brands include CCI, Federal, PMC, Remington, Speer, Wolf and Winchester.

Measurements are primarily made using a Leica FS M 2D reflectance microscope, and a Nanofocus uSurf disc scanning confocal microscope. The former captures photo images while the latter captures 3D topographies. Detailed metadata are available for each of these images, for example for photo images, the magnification was 2X with a lateral resolution of $2.53 \mu m$, producing $2592 \times 1944$ pixel, 256-grayscale PNG images. For 3D, various magnifications were used, for example an objective of 10X results in a lateral resolution of $3.125 \mu m$, and images that are around $1200 \times 1200$. The 3D data are in x3p format, and more information about this file format can be found in Chapter \@ref(bullets). 

Examples of images are in Section \@ref(casings-caseStudy).


## R Package(s)
The goal of the analysis is to derive a measure of similarity between a pair of cartridge case images. There are a few steps involved in such an analysis. Broadly, we first need to process the images so that they are ready for analysis. This might involve selecting relevant marks or highlighting specific features. Next, given two images, they need to be aligned so that any similarity measure extracted is meaningful. The final step is to estimate the similarity score.

We have developed R packages to analyze images in the standard format in NIST's database. [`cartridges`](https://github.com/xhtai/cartridges) analyzes 2D photo images, while [`cartridges3D`](https://github.com/xhtai/cartridges3D) analyzes 3D topographies. A complete description of methodology used in `cartridges` is in @Tai2018. `cartridges3D` modifies this for 3D topographies, with the major difference being in pre-processing. **[[write about this in package readme]]**

The primary functions of the package are `allPreprocess` and `calculateCCFmax`. The former performs all pre-processing steps, while the latter does both alignment and computation of a similarity score. The corresponding functions for 3D are `allPreprocess3D` and **[[package needs to be updated]]**. The end result is a similarity score for a pair of images being compared. 

## Drawing Conclusions {#casings-conclusions}
Depending on the goal of the analysis, as well as the availability of data, there are a few ways in which conclusions may be drawn. The analysis produces a similarity score for a pair of images. This could be sufficient for the analysis, for example if we have two pairs of images being compared, the goal might be simply to estimate which of the two pairs are more similar to each other. 

In other situations, it might be appropriate to designate a similarity cutoff above which some action is taken. The selection of such a cutoff depends on the goal. For example, if the cutoff is meant to select pairs that warrant further manual investigation, a lower cutoff might be set to ensure high recall. On the other hand, if the cutoff is meant to declare a pair to be a match, potentially implicating someone in a crime, a very high prediction would be necessary. Figure **[[insert figure]]** shows the tradeoff between precision and recall as we vary the cutoff, for a particular set of data.

Given appropriate data on the distribution of similarity scores for non-matching pairs in some population of interest, a third type of conclusion that we can draw is to estimate a probability of getting a higher similarity score by chance. For example, if we obtain a similarity of .7 for the pair of interest, we compare .7 to some distribution of similairty scores for non-matching pairs, that might have been obtained from prior studies. The probability of interest is the probability that a random draw from that distribution is larger than .7, say $p_0$. The conclusion that we can then draw is that if the pair was a non-match, the probability of getting a score higher than .7 is $p_0$. If the value of $p_0$ is small, this provides evidence against the hypothesis that the pair of interest is a non-matching pair.


## Case Study {#casings-caseStudy}
The following case study uses the same pair of images as in the Examples section of the `cartridges` package [README](https://github.com/xhtai/cartridges). These are 2D photo images from the NBIDE study in NIST's database, coming from the same Ruger gun, firing PMC ammunition. The raw data is also available from within the package.

We first load the package:
```{r}
# devtools::install_github("xhtai/cartridges")
library(cartridges)
```

We can read in and plot the images as follows. If using a downloaded image, one can simply replace `system.file("extdata", "NBIDE R BF 118.png", package = "cartridges")` with the location of the downloaded image.

```{r, fig.width = 4, fig.height = 3}
exampleImage <- cartridges::readCartridgeImage(system.file("extdata", "NBIDE R BF 118.png", package = "cartridges"))
cartridges::plotImage(exampleImage, type = "original")
exampleImage2 <- cartridges::readCartridgeImage(system.file("extdata", "NBIDE R BF 129.png", package = "cartridges"))
cartridges::plotImage(exampleImage2, type = "original")
```

Now, all the pre-processing can be done using `allPreprocess(exampleImage)`. The processed images can be plotted using `plotImage`. The pre-processed images are available within the package as `processedExample` and `processedExample2`.

```{r, fig.width = 3, fig.height = 3}
cartridges::plotImage(processedExample, type = "any")
cartridges::plotImage(processedExample2, type = "any")
```

Now, to compare these two images, we use 

```{r, eval=FALSE}
calculateCCFmax(processedExample, processedExample2)
```

This produces a score of .36. As discussed in Section \@ref(casings-conclusions), the conclusions to be drawn depend on the goals of the analysis, as well as the availability of data. The first type of conclusion could be that this pair of images is more similar to each other than some other pair of images. The second type of conclusion could be that this score is high enough to warrant further manual investigation. Finally, if we have some prior information on some reference distribution of non-matching scores, we can compute the probability of obtaining a higher score by chance as follows. Here we use a normal distribution for purposes of illustration.

```{r}
computeProb(.36, rnorm(50, .02, .3))
```

The conclusion then is that the probability of obtaining a score higher than .36, for a non-matching pair, is .16.

talk about linkages?

TODO:

- put linkages code in 2D and 3D?
- put prob code in 3D
- more detail in 3D readme

