# Digital Evidence: Online behavior {#digital1}

## Introduction

Online anonymous marketplaces are digital marketplaces that provide anonymity protections beyond traditional marketplaces such as Amazon and eBay [@Soska2015]. They run on the dark web using anonymizing browsers such as Tor, and payment is typically made using cryptocurrencies such as Bitcoin. Because of such anonymity protections, these marketplaces are most commonly used for the sale of illicit products, in particular, drugs. Silk Road, an early such marketplace, began in February 2011, and was shut down by law enforcement in October 2013. Since then, other marketplaces have opened and closed; sellers have done business on multiple marketplaces concurrently, as well as moved between marketplaces **[[cite?]]**. By conducting such business, sellers invariably leave evidence of criminal activity. These marketplaces are in the public domain, and anyone with some level of technological skills would be able to browse user profiles and products sold through these marketplaces and accounts. To put it simply, these sellers hide in plain sight, and the forensic challenge then is to track down the real-world individuals behind these accounts.

Law enforcement has made over 100 marketplace-related arrests **[[cite]]** from **when** to **when**. Often, linking accounts on the same or on different marketplaces helps investigators track down real-world individuals, in the same way that matching pattern evidence in other forensic disciplines helps to generate leads in investigations. To this end, law enforcement officers have been known to try to link various online accounts. Based on descriptions in court records, investigators have used techniques such as manually matching account handles, PGP keys **[[explain what these are]]**, items sold, as well as searched forum discussions for account mentions **[[cite criminal complaints]]**. All of these rely on manual investigation, which can be lengthy and time-consuming.

In this chapter, we describe an R package, `heisenbrgr`, that implements an automated method to derive similarity scores between pairs of accounts. If used on a database of accounts, this can be used to generate candidate accounts that belong to the same real-world individuals. Automated techniques can be especially useful in searching such databases, generating leads in cases where there are no obvious signs pointing towards multiple account ownership. Examples are when there are no other accounts with the same handle, when sellers do not post PGP keys, and in the absence of forum discussions about the seller of interest.

**[[add literature?]]**

## Data 
The data come directly from various marketplaces. One can simply open an account on a marketplace, and access seller profiles as well as item listings. Examples are in Figures \@ref(fig:dreamProfile) and \@ref(fig:dreamProduct).

```{r dreamProfile, echo=FALSE, fig.cap='Example profile page on Dream market'}
knitr::include_graphics("img/digital_dreamProfile.png")
```

```{r dreamProduct, echo=FALSE, fig.cap='Example product page on Dream market'}
knitr::include_graphics("img/digital_productPage.png")
```

Now, there are various levels of analysis that are possible, and the data required depends on the level desired. Briefly, information associated with an account can be extracted from the pages shown in Figures \@ref(fig:dreamProfile) and \@ref(fig:dreamProduct). For a pair of accounts to be compared, various similarity measures can then be derived, for example the edit distance between their handles, or the difference in length of their profile descriptions. Given a large number of such pairs, and using heuristics for labels, we train a supervised random forest model. Full details can be found in **[[cite KDD paper for methodology]]**. Now, for a new pair of accounts, we can simply feed this information into the model to generate a prediction for whether or not the pair belongs to the same seller. 

The simplest type of analysis would be to directly feed the model values for each of the similarity measures for a pairwise comparison that is of interest. Some of these can be derived simply using a manual examination, for example, the edit distance between the handles, whether or not the pair is from the same marketplace, and the difference between the number of feedback that each account has. Missing values are also allowed. 

The next type of analysis is to feed in account-level data, that can be typed or copied from the webpages, and use the R package to generate pairwise similarity measures, that are subsequently used to generate a prediction. These two types of analysis are the focus of this chapter, and will be detailed in Section \@ref(digital-caseStudy).

The most comprehensive analysis that can be done is if the user has access to a large data set that can be used to retrain the classifier. We provide a brief description here, but this will not be the focus; we encourage the interested reader to refer to the package [documentation](https://github.com/xhtai/heisenbrgr), where more information is available. The model that has been pre-trained uses data from 12 marketplaces over a 7-year period **[[cite KDD]]**, and various modeling choices were made, such as down-sampling negative examples. The user might consider retraining the model if they have data of interest that are substantially different, or if different modeling choices are desired. Some examples could be if the data collection interval is much shorter, or if they would like to restrict attention to a particular marketplace.

In order to retrain the model, a much larger collection of data is required. There exist publicly available, anonymized marketplace scrapes in the required format [here](https://arima.cylab.cmu.edu/markets/cybercrime.php). The pre-trained model uses this database in its de-anonymized form, and it is possible to request for this through the same website. Alternatively, there are various tools that have been developed for scraping pages on the dark web (see @Christin2013, @Soska2015), and one can use these to collect scrapes of profiles and item listings. These scrapes then need to be parsed, to generate (at a minimum) the following information: unique users with handles and marketplaces, associated item titles and their associated feedback received. There should also be some means of generating labels for training.

A fuller analysis can be done if timestamped scrapes of profiles and item listings can be collected over a period, and `heisenbrgr` also provides utilties for handling such data. 

## R Package(s) {#marketplaces-package}
The goal is to produce a measure of similarity between pairs of accounts. A complete dscription of the methodology is in **[[cite KDD paper]]**, with the accompanying R package [`heisenbrgr`](https://github.com/xhtai/heisenbrgr). 

Given information associated with an account that can be scraped or input manually, it can be input using `someFunction`, and a prediction can then be generated from a pre-trained model using `someFunction`. This prediction is the desired end result.

To retrain the model, processing can be done using `someFunctions`, ...

## Drawing Conclusions
The conclusions to be drawn mirror that in Section \@ref(casings-conclusions). Here the analysis produces a proportion of classifier votes in favor of a match, which can be interpreted as a similarity score. There are three subsequent types of conclusions that can be inferred, depending on the goal of the analysis.

First, the score can be used to rank pairs based on similarity. This can be a simple conclusion such as one pair being more similar than a different pair. Another possible situation might be when we have a database with information on various accounts, and are interested in the top 10 accounts most similar to an account being investigated.

The second type of analysis that can be done is to set some cutoff on similarity score, above which some action is taken. The tradeoff between precision and recall as the cutoff changes is shown in Figure **[[insert figure]]**. Again, the cutoff to be set depends on the particular scenario. As described in Section \@ref(casings-conclusions), if the cutoff is meant to select pairs for manual investigation, then a low cutoff corresponding to high recall but low precision is favorable, whereas if the score is to be used as evidence against a particular individual, a high cutoff is necessary.

Finally, if appropriate data are available on the distribution of non-matching scores for some population of interest, it is then possible to estimate a probability of obtaining a higher score by chance, which can serve as a measure of the weight of evidence. 



## Case Study {#digital-caseStudy}



TODO:

- input account-level data
- input similarity scores
- for own database to retrain --- some means of putting in non-PGP labels
- remove identifying information from screenshots
